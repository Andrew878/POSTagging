from nltk.corpus import brown
from nltk import FreqDist, WittenBellProbDist
from nltk import ngrams, bigrams
from nltk.parse import viterbi

import Viterbi as vit
import ErrorAnalysis as error


def tag_all_sentences_viterbi(test_sents, freq_dist_tag_single, freq_dist_tag_single_SMOOTH,
                              freq_dist_tagWordPair_SMOOTH,
                              freq_dist_tagBigram_SMOOTH, freq_dist_tagWordPairWithStartEnd_SMOOTH):
    tag_estimated_by_viterbi = []

    for test_sent in test_sents:
        tag_sequence = vit.viterbi_path(test_sent, freq_dist_tag_single, freq_dist_tag_single_SMOOTH,
                                        freq_dist_tagWordPair_SMOOTH,
                                        freq_dist_tagBigram_SMOOTH, freq_dist_tagWordPairWithStartEnd_SMOOTH)
        tag_estimated_by_viterbi.append(tag_sequence)

    return tag_estimated_by_viterbi


start = '<s>'
end = '</s>'
max_sentence_length = 101
sents = brown.tagged_sents(tagset='universal')

sents = [[(start, start)] + sent + [(end, end)] for sent in sents if len(sent) < max_sentence_length]

train_size = 1000
test_size = 500
train_sents = sents[:train_size]
test_sents = sents[train_size:train_size + test_size]

train_words_individual = [[]] * len(train_sents)
train_tags_individual = [[]] * len(train_sents)
# test_words_individual = [[]] * len(test_sents)
# test_tags_individual = [[]] * len(test_sents)
test_words_individual = []
test_tags_individual = []

freq_dist_tag_single = FreqDist()
freq_dist_tagWordPair = FreqDist()
freq_dist_tagWordPairWithStartEnd = FreqDist()
freq_dist_tagBigram = FreqDist()

j = 0
for sent in train_sents:
    word_list = [w for (w, _) in sent]
    tag_list = [t for (_, t) in sent]

    freq_dist_tag_single += FreqDist(tag_list)
    freq_dist_tagWordPair += FreqDist(sent[1:-1])
    freq_dist_tagBigram += FreqDist(bigrams(tag_list))
    # skip the special start/end characters
    freq_dist_tagWordPairWithStartEnd += FreqDist(sent)

    train_words_individual[j].insert(0, word_list)
    train_tags_individual[j].insert(0, tag_list)
    j += 1

j = 0
for sent in test_sents:
    word_list = [w for (w, _) in sent]
    tag_list = [t for (_, t) in sent]

    test_words_individual.append(word_list)
    test_tags_individual.append(tag_list)
    j += 1

# print(train_words_individual[0][:])
# print(freq_dist_tag_single.most_common(15))
# print(freq_dist_tagWordPair.most_common(15))
# print(freq_dist_tagBigram.most_common(15))

print("")

freq_dist_tag_single_SMOOTH = WittenBellProbDist(freq_dist_tag_single, bins=1e5)
freq_dist_tagWordPair_SMOOTH = WittenBellProbDist(freq_dist_tagWordPair, bins=1e5)
freq_dist_tagWordPairWithStartEnd_SMOOTH = WittenBellProbDist(freq_dist_tagWordPairWithStartEnd, bins=1e5)
freq_dist_tagBigram_SMOOTH = WittenBellProbDist(freq_dist_tagBigram, bins=1e5)

print(test_sents[0])
# test_sent_tags_est = vit.viterbi_path(test_words_individual[0], freq_dist_tag_single, freq_dist_tag_single_SMOOTH, freq_dist_tagWordPair_SMOOTH,
#                  freq_dist_tagBigram_SMOOTH, freq_dist_tagWordPairWithStartEnd_SMOOTH)

all_test_sent_tags_est = tag_all_sentences_viterbi(test_words_individual, freq_dist_tag_single,
                                                   freq_dist_tag_single_SMOOTH, freq_dist_tagWordPair_SMOOTH,
                                                   freq_dist_tagBigram_SMOOTH, freq_dist_tagWordPairWithStartEnd_SMOOTH)

overall_error, overall_N, overall_large_error_index = error.measure_performance_all_sentence(test_tags_individual, all_test_sent_tags_est)


