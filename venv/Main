from nltk.corpus import brown
from nltk import FreqDist, WittenBellProbDist
from nltk import ngrams, bigrams
from nltk import tag
from nltk.parse import viterbi

import Viterbi as vit
import ErrorAnalysis as error
import BeamSearch


def tag_all_sentences_viterbi(test_sents, freq_dist_tag_single, freq_dist_tag_single_SMOOTH,
                              freq_dist_tagWordPair_SMOOTH,
                              freq_dist_tagBigram_SMOOTH, freq_dist_tagWordPairWithStartEnd_SMOOTH):
    tag_estimated_by_viterbi = []

    for test_sent in test_sents:
        tag_sequence = vit.viterbi_path(test_sent, freq_dist_tag_single, freq_dist_tag_single_SMOOTH,
                                        freq_dist_tagWordPair_SMOOTH,
                                        freq_dist_tagBigram_SMOOTH, freq_dist_tagWordPairWithStartEnd_SMOOTH)
        tag_estimated_by_viterbi.append(tag_sequence)

    return tag_estimated_by_viterbi


def tag_all_sentences_beam(test_sents, freq_dist_tag_single, freq_dist_tag_single_SMOOTH,
                           freq_dist_tagWordPair_SMOOTH,
                           freq_dist_tagBigram_SMOOTH, freq_dist_tagWordPairWithStartEnd_SMOOTH, beam_width):
    tag_estimated_by_viterbi = []
    # minus two to remove start and end tags
    beam_search_vit = BeamSearch.BeamSearch(beam_width)

    i=0
    for test_sent in test_sents:
        print ("Sent index", i)
        tag_sequence = beam_search_vit.viterbi_path(test_sent, freq_dist_tag_single, freq_dist_tag_single_SMOOTH,
                                                    freq_dist_tagWordPair_SMOOTH,
                                                    freq_dist_tagBigram_SMOOTH,
                                                    freq_dist_tagWordPairWithStartEnd_SMOOTH)
        tag_estimated_by_viterbi.append(tag_sequence)
        i += 1
    return tag_estimated_by_viterbi


start = '<s>'
end = '</s>'
max_sentence_length = 101
sents = brown.tagged_sents(tagset='universal')

sents = [[(start, start)] + sent + [(end, end)] for sent in sents if len(sent) < max_sentence_length]

train_size = 1000 #100.
test_size = 5
train_sents = sents[:train_size]
test_sents = sents[train_size:train_size + test_size]

train_words_individual = [[]] * len(train_sents)
train_tags_individual = [[]] * len(train_sents)
# test_words_individual = [[]] * len(test_sents)
# test_tags_individual = [[]] * len(test_sents)
test_words_individual = []
test_tags_individual = []

freq_dist_tag_single = FreqDist()
freq_dist_tagWordPair = FreqDist()
freq_dist_tagWordPairWithStartEnd = FreqDist()
freq_dist_tagBigram = FreqDist()

unique_tag_dict = dict.fromkeys(freq_dist_tag_single.keys())

j = 0
for sent in train_sents:
    word_list = [w for (w, _) in sent]
    tag_list = [t for (_, t) in sent]

    freq_dist_tag_single += FreqDist(tag_list)
    freq_dist_tagWordPair += FreqDist(sent[1:-1])
    freq_dist_tagBigram += FreqDist(bigrams(tag_list))
    # skip the special start/end characters
    freq_dist_tagWordPairWithStartEnd += FreqDist(sent)

    train_words_individual[j].insert(0, word_list)
    train_tags_individual[j].insert(0, tag_list)
    j += 1

j = 0
for sent in test_sents:
    word_list = [w for (w, _) in sent]
    tag_list = [t for (_, t) in sent]

    test_words_individual.append(word_list)
    test_tags_individual.append(tag_list)
    j += 1

# print(train_words_individual[0][:])
# print(freq_dist_tag_single.most_common(15))
# print(freq_dist_tagWordPair.most_common(15))
# print(freq_dist_tagBigram.most_common(15))

print("")

freq_dist_tag_single_SMOOTH = WittenBellProbDist(freq_dist_tag_single, bins=1e5)
freq_dist_tagWordPair_SMOOTH = WittenBellProbDist(freq_dist_tagWordPair, bins=1e5)
freq_dist_tagWordPairWithStartEnd_SMOOTH = WittenBellProbDist(freq_dist_tagWordPairWithStartEnd, bins=1e5)
freq_dist_tagBigram_SMOOTH = WittenBellProbDist(freq_dist_tagBigram, bins=1e5)

# test_sent_tags_est = vit.viterbi_path(test_words_individual[0], freq_dist_tag_single, freq_dist_tag_single_SMOOTH, freq_dist_tagWordPair_SMOOTH,
#                  freq_dist_tagBigram_SMOOTH, freq_dist_tagWordPairWithStartEnd_SMOOTH)

test_words_to_tag = test_words_individual
test_sent_tags_act = test_tags_individual

print("Sentence:", test_words_individual)
print("tags:", test_tags_individual)

# all_test_sent_tags_est = tag_all_sentences_viterbi(test_words_to_tag, freq_dist_tag_single,
#                                                    freq_dist_tag_single_SMOOTH, freq_dist_tagWordPair_SMOOTH,
#                                                    freq_dist_tagBigram_SMOOTH, freq_dist_tagWordPairWithStartEnd_SMOOTH)


# beam_search_vit = BeamSearch.BeamSearch(len(list(freq_dist_tag_single.keys())))
#
# test_sent_tags_est_beam = beam_search_vit.viterbi_path(test_words_to_tag, freq_dist_tag_single, freq_dist_tag_single_SMOOTH, freq_dist_tagWordPair_SMOOTH,
#                  freq_dist_tagBigram_SMOOTH, freq_dist_tagWordPairWithStartEnd_SMOOTH)

all_test_sent_tags_est_beam_all = tag_all_sentences_beam(test_words_to_tag, freq_dist_tag_single,
                                                         freq_dist_tag_single_SMOOTH, freq_dist_tagWordPair_SMOOTH,
                                                         freq_dist_tagBigram_SMOOTH,
                                                         freq_dist_tagWordPairWithStartEnd_SMOOTH,
                                                         len(list(freq_dist_tag_single.keys())) - 2)

# all_test_sent_tags_est_beam_one = tag_all_sentences_beam(test_words_to_tag, freq_dist_tag_single,
#                                                    freq_dist_tag_single_SMOOTH, freq_dist_tagWordPair_SMOOTH,
#                                                    freq_dist_tagBigram_SMOOTH, freq_dist_tagWordPairWithStartEnd_SMOOTH, 1)

all_test_sent_tags_est_beam_five = tag_all_sentences_beam(test_words_to_tag, freq_dist_tag_single,
                                                          freq_dist_tag_single_SMOOTH, freq_dist_tagWordPair_SMOOTH,
                                                          freq_dist_tagBigram_SMOOTH,
                                                          freq_dist_tagWordPairWithStartEnd_SMOOTH, 3)

# print(error.measure_performance_all_sentence(test_sent_tags_act, all_test_sent_tags_est ))
#
#
# print(error.measure_performance_all_sentence(test_sent_tags_act, test_sent_tags_est_beam))

# print("normal viterbi")
# overall_error, overall_N, overall_large_error_index = error.measure_performance_all_sentence(test_sent_tags_act, all_test_sent_tags_est, unique_tag_dict)
# print("beam search viterbi")
# overall_error, overall_N, overall_large_error_index = error.measure_performance_all_sentence(test_sent_tags_act, all_test_sent_tags_est_beam , unique_tag_dict)


# overall_error, overall_N, overall_large_error_index = error.measure_performance_all_sentence(test_sent_tags_act, all_test_sent_tags_est, unique_tag_dict)
#
# error.get_confusion_matrix_for_sent_size(test_sent_tags_act,all_test_sent_tags_est, 100)
error.get_confusion_matrix_for_sent_size(test_sent_tags_act, all_test_sent_tags_est_beam_all, 100)
# error.get_confusion_matrix_for_sent_size(test_sent_tags_act,all_test_sent_tags_est_beam_one, 100)
error.get_confusion_matrix_for_sent_size(test_sent_tags_act, all_test_sent_tags_est_beam_five, 100)

# error.compare_two_approaches(test_sent_tags_act, all_test_sent_tags_est_beam_all, "beam all",
#                              all_test_sent_tags_est_beam_five, "beam 5")
